{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "065725d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# Display all columns\n",
    "pd.set_option('display.max_columns', None)\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "from collections import Counter\n",
    "from numpy import where\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from numpy import mean\n",
    "from sklearn.decomposition import FastICA, PCA\n",
    "from scipy.stats import kurtosis \n",
    "from sklearn import random_projection\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2986e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61f3684e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 91713 rows and 85 columns.\n",
      "(91713, 123)\n"
     ]
    }
   ],
   "source": [
    "df_patient = pd.read_csv(\"data/patientSurvivalPredication.csv\")\n",
    "\n",
    "assert df_patient.shape[0] > 0\n",
    "assert df_patient.shape[1] > 0\n",
    "\n",
    "print(f\"Data has {df_patient.shape[0]} rows and {df_patient.shape[1]} columns.\")\n",
    "\n",
    "df_patient.drop(['encounter_id', 'patient_id', 'hospital_id', 'Unnamed: 83'], inplace=True, axis=1)\n",
    "\n",
    "df_patient.fillna(-1, inplace=True)\n",
    "\n",
    "# Replace -1 with empty string in string columns types\n",
    "df_patient['ethnicity'].replace(-1, '', inplace=True)\n",
    "df_patient['gender'].replace(-1, '', inplace=True)\n",
    "df_patient['icu_stay_type'].replace(-1, \"\", inplace=True)\n",
    "df_patient['icu_admit_source'].replace(-1, '', inplace=True)\n",
    "df_patient['icu_type'].replace(-1, '', inplace=True)\n",
    "df_patient['apache_3j_bodysystem'].replace(-1, '', inplace=True)\n",
    "df_patient['apache_2_bodysystem'].replace(-1, '', inplace=True)\n",
    "\n",
    "# Encode ethinicity as decision tree can't handle string values\n",
    "enc = LabelEncoder()\n",
    "enc.fit(df_patient['ethnicity'])\n",
    "\n",
    "# Correct different spelling for same values\n",
    "df_patient['apache_2_bodysystem'].replace(\"Undefined diagnoses\", \"Undefined Diagnoses\", inplace=True)\n",
    "\n",
    "# Create dummy columns for string columns so decision tree can proccess them\n",
    "df_patient = pd.get_dummies(df_patient, columns=[\"ethnicity\", \"gender\", \"icu_stay_type\", \"icu_admit_source\", \"icu_type\", \"apache_3j_bodysystem\", \"apache_2_bodysystem\"], prefix=[\"ethnicity_is\", \"gender_is\", \"icu_stay_type_is\", \"icu_admit_source_is\", \"icu_type_is\", \"apache_3j_bodysystem_is\", \"apache_2_bodysystem_is\"] )\n",
    "\n",
    "print(df_patient.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26f6e164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has 100000 rows and 299 columns.\n"
     ]
    }
   ],
   "source": [
    "df_insurance = pd.read_csv('data/insurance/train.csv', nrows=100000)\n",
    "\n",
    "assert df_insurance.shape[0] > 0\n",
    "assert df_insurance.shape[1] > 0\n",
    "\n",
    "print(f\"Data has {df_insurance.shape[0]} rows and {df_insurance.shape[1]} columns.\")\n",
    "\n",
    "def encode_labels(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype=='object':\n",
    "            label = LabelEncoder()\n",
    "            label.fit(list(df[column].values))\n",
    "            df[column] = label.transform(list(df[column].values))\n",
    "    return df\n",
    "\n",
    "df_insurance = df_insurance.drop(['QuoteNumber'], axis=1)\n",
    "\n",
    "# Now convert the date to day, month and week and drop the date\n",
    "df_insurance['Date'] = pd.to_datetime(pd.Series(df_insurance['Original_Quote_Date']))\n",
    "df_insurance = df_insurance.drop('Original_Quote_Date', axis=1)\n",
    "df_insurance['Year'] = df_insurance['Date'].apply(lambda x: int(str(x)[:4]))\n",
    "df_insurance['Month'] = df_insurance['Date'].apply(lambda x: int(str(x)[5:7]))\n",
    "df_insurance['weekday'] = df_insurance['Date'].dt.dayofweek\n",
    "df_insurance = df_insurance.drop('Date', axis=1)\n",
    "df_insurance = encode_labels(df_insurance)\n",
    "df_insurance = df_insurance.fillna(-1)\n",
    "\n",
    "insurance_X = df_insurance.loc[:, df_insurance.columns != 'QuoteConversion_Flag']\n",
    "insurance_Y = df_insurance['QuoteConversion_Flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f604902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline \n",
    "\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.1)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under)]\n",
    "\n",
    "patient_Y = df_patient['hospital_death']\n",
    "patient_X = df_patient.loc[:, df_patient.columns != 'hospital_death']\n",
    "patient_X_resample, patient_Y_resample = Pipeline(steps=steps).fit_resample(patient_X, patient_Y)\n",
    "\n",
    "patient_X_resample_scaled = StandardScaler().fit_transform(patient_X_resample) \n",
    "\n",
    "over = SMOTE(sampling_strategy=0.3)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('over', over), ('under', under)]\n",
    "\n",
    "insurance_X = df_insurance.loc[:, df_insurance.columns != 'QuoteConversion_Flag']\n",
    "insurance_Y = df_insurance['QuoteConversion_Flag']\n",
    "insurance_X_resample, insurance_Y_resample = Pipeline(steps=steps).fit_resample(insurance_X, insurance_Y)\n",
    "\n",
    "insurance_X_resample_scaled = StandardScaler().fit_transform(insurance_X_resample) \n",
    "\n",
    "patient_X_train, patient_X_test, patient_y_train, patient_y_test = train_test_split(np.array(patient_X_resample),np.array(patient_Y_resample), test_size=0.15)\n",
    "insurance_X_train, insurance_X_test, insurance_y_train, insurance_y_test = train_test_split(np.array(insurance_X_resample),np.array(insurance_Y_resample), test_size=0.15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2dc025ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9594078030316471\n",
      "Train time: 19.47288703918457\n",
      "Query time: 0.02012801170349121\n",
      "Test ROC AUC: 0.8655171070064688\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.01)\n",
    "X_train, X_test, y_train, y_test = train_test_split(insurance_X_resample_scaled, insurance_Y_resample, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20, scoring=\"roc_auc\").mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test ROC AUC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6983dcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f56d6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9417885449940547\n",
      "Train time: 7.147889852523804\n",
      "Query time: 0.003490924835205078\n",
      "Test ROC AUC: 0.8454013654562001\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=80).fit(insurance_X_resample_scaled)\n",
    "pca_insurance_X_resample_scaled = pca.transform(insurance_X_resample_scaled)\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.01)\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_insurance_X_resample_scaled, insurance_Y_resample, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20, scoring=\"roc_auc\").mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test ROC AUC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5de01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8a56713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.860120087646347\n",
      "Train time: 5.598322868347168\n",
      "Query time: 0.0029449462890625\n",
      "Test ROC AUC: 0.766790758240345\n"
     ]
    }
   ],
   "source": [
    "ica = FastICA(n_components=59, max_iter=10000, tol=0.1).fit(insurance_X_resample_scaled)\n",
    "ica_insurance_X_resample_scaled = ica.transform(insurance_X_resample_scaled)\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.01)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ica_insurance_X_resample_scaled, insurance_Y_resample, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20, scoring=\"roc_auc\").mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test ROC AUC: \" + str(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9002b42a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.7655831858223455\n",
      "Train time: 3.5977699756622314\n",
      "Query time: 0.003618955612182617\n",
      "Test ROC AUC: 0.6484668704798361\n"
     ]
    }
   ],
   "source": [
    "rp = random_projection.SparseRandomProjection(n_components=24)\n",
    "rp_insurance_X_resample_scaled=rp.fit_transform(insurance_X_resample_scaled)\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.01)\n",
    "X_train, X_test, y_train, y_test = train_test_split(rp_insurance_X_resample_scaled, insurance_Y_resample, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20, scoring=\"roc_auc\").mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test ROC AUC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "560a491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation score: 0.9461288144325737\n",
      "Train time: 9.098109006881714\n",
      "Query time: 0.00372314453125\n",
      "Test ROC AUC: 0.8580776281818915\n"
     ]
    }
   ],
   "source": [
    "tsvd = TruncatedSVD(n_components=94)\n",
    "tsvd_insurance_X_resample_scaled = tsvd.fit_transform(insurance_X_resample_scaled)\n",
    "\n",
    "clf = MLPClassifier(max_iter= 5000, hidden_layer_sizes=(5,2), activation='logistic', verbose=False, learning_rate_init=0.01)\n",
    "X_train, X_test, y_train, y_test = train_test_split(tsvd_insurance_X_resample_scaled, insurance_Y_resample, test_size=0.2)\n",
    "\n",
    "cv_score = cross_val_score(clf, X_train, y_train, cv=20, scoring=\"roc_auc\").mean()\n",
    "print(\"Cross validation score: \" + str(cv_score))\n",
    "\n",
    "start = time.time()\n",
    "clf.fit(X_train, y_train)\n",
    "train_time = time.time() - start\n",
    "print(\"Train time: \" + str(train_time))\n",
    "\n",
    "start = time.time()\n",
    "y_pred = clf.predict(X_test)\n",
    "query_time = time.time() - start\n",
    "print(\"Query time: \" + str(query_time))\n",
    "\n",
    "score = roc_auc_score(y_test, y_pred)\n",
    "print(\"Test ROC AUC: \" + str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122392c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
